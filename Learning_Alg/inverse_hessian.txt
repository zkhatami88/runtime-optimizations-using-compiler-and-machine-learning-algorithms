
 ====================

The values of training data are : 
0.1	0.85	0.2	0.34	0
0.15	0.8	0.25	0.1	0
0.2	0.75	0.35	0.15	1
0.25	0.7	0.35	0.3	0
0.3	0.65	0.2	0.1	1
0.35	0.6	0.25	0.3	0
0.4	0.55	0.3	0.15	1
0.45	0.5	0.35	0.45	0
0.5	0.45	0.2	0.2	1
0.55	0.4	0.25	0.5	0
0.6	0.35	0.3	0.2	1
0.65	0.3	0.35	0.6	0
0.7	0.25	0.2	0.3	1
0.75	0.2	0.25	0.6	0
0.8	0.15	0.3	0.5	1
0.85	0.1	0.35	0.7	0
0.1	0.4	0.25	0.2	1
0.15	0.35	0.3	0.4	0
0.2	0.3	0.35	0.3	1
0.25	0.25	0.4	0.5	0
0.3	0.2	0.45	0.4	1
0.35	0.15	0.35	0.6	0
0.4	0.1	0.3	0.4	1
0.45	0.5	0.25	0.4	0
0.5	0.45	0.2	0.25	1
0.55	0.4	0.15	0.35	0
0.6	0.35	0.1	0.2	1
0.65	0.3	0.3	0.6	0
0.7	0.2	0.25	0.5	1
0.75	0.15	0.2	0.6	0
0.2	0.5	0.4	0.1	1
0.25	0.45	0.35	0.5	0
0.3	0.4	0.3	0.2	1
0.35	0.35	0.25	0.4	0
0.4	0.3	0.2	0.3	1
0.4	0.35	0.15	0.45	0
0.45	0.4	0.1	0.15	1
0.5	0.45	0.25	0.5	0
0.55	0.5	0.2	0.2	1
0.6	0.35	0.15	0.5	0
0.4	0.5	0.4	0.1	1

 ====================


Binary logistic regression model : 


 det is : 0.00816514
(0)	Least_squared_err =	2.13656
weights[0] = 5.75025	weights[1] = 2.25083	weights[2] = -6.99001	weights[3] = 3.69822	weights[4] = -14.0991	
----------

 det is : 0.000375987
(1)	Least_squared_err =	0.654202
weights[0] = 8.59783	weights[1] = 5.67188	weights[2] = -12.4596	weights[3] = 10.4088	weights[4] = -25.2916	
----------

 det is : 1.46335e-05
(2)	Least_squared_err =	0.372918
weights[0] = 11.2312	weights[1] = 10.2496	weights[2] = -18.5256	weights[3] = 20.4236	weights[4] = -38.9046	
----------

 det is : 5.33168e-07
(3)	Least_squared_err =	0.280264
weights[0] = 14.6471	weights[1] = 16.391	weights[2] = -26.7695	weights[3] = 34.506	weights[4] = -57.0133	
----------

 det is : 1.9628e-08
(4)	Least_squared_err =	0.210828
weights[0] = 20.0691	weights[1] = 24.213	weights[2] = -38.3535	weights[3] = 52.1095	weights[4] = -81.6324	
----------

 det is : 4.49027e-10
(5)	Least_squared_err =	0.134488
weights[0] = 27.7855	weights[1] = 33.561	weights[2] = -53.2582	weights[3] = 72.4046	weights[4] = -112.838	
----------

 det is : 4.73017e-12
(6)	Least_squared_err =	0.0765251
weights[0] = 37.5432	weights[1] = 44.0874	weights[2] = -71.0935	weights[3] = 95.0689	weights[4] = -149.523	
----------
Learning has been done!

weights[%i] = 37.54320
weights[%i] = 44.08741
weights[%i] = -71.09352
weights[%i] = 95.06893
weights[%i] = -149.5234
